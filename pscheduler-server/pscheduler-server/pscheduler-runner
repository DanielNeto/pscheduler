#!/usr/bin/python
#
# Execute runs of tasks and put the results into the database.
#

# TODO: Replace requests.* with pscheduler equivalents.

# TODO: See which of these are still needed.
import datetime
import detach
import errno
import json
import optparse
import os
import pscheduler
import psycopg2
import psycopg2.extensions
import requests
import select
import signal
import subprocess
import sys
import time
import traceback

from dateutil.tz import tzlocal


# Gargle the arguments

opt_parser = optparse.OptionParser()

opt_parser.add_option("-c", "--channel",
                      help="Schedule notification channel",
                      action="store", type="string", dest="channel",
                      default="run_change")

# TODO: Do we want pscheduler as the default here?
opt_parser.add_option("-d", "--dsn",
                      help="Database connection string",
                      action="store", type="string", dest="dsn",
                      default="dbname=pscheduler")

# NOTE: Changing the refresh interval will have an effect on how many
# forked processes are running, connected to the database and waiting
# for a run to start.  Increase this value only if you understand the
# consequences.
opt_parser.add_option("-r", "--refresh",
                      help="Forced refresh interval (ISO8601)",
                      action="store", type="string", dest="refresh",
                      default="PT1M")

opt_parser.add_option("--verbose", action="store_true", dest="verbose")
opt_parser.add_option("--debug", action="store_true", dest="debug")

(options, args) = opt_parser.parse_args()

refresh = pscheduler.iso8601_as_timedelta(options.refresh)
if refresh is None:
    opt_parser.error('Invalid refresh interval "' + options.refresh + '"')
if pscheduler.timedelta_as_seconds(refresh) == 0:
    opt_parser.error("Refresh interval must be calculable as seconds.")


log = pscheduler.Log(verbose=options.verbose, debug=options.debug)

dsn = options.dsn



#
# Runs and things we do with them
#
class Run:

    def __init__(self, id, start_in):

        try:

            # TODO: May not want to fully detach so children die with
            # the parent.

            with detach.Detach(close_fds=False,
                               stdout=sys.stdout,
                               stderr=sys.stderr) as detacher:

                if detacher.pid:
                    self.pid = detacher.pid
                    return

                log.debug("Started runner for ID %d", id)
                self._run(id, start_in)

        except:
            log.exception()


    # This method does the dirty work.  Don't worry about catching
    # exception; that's the caller's responsibility.
    def _run(self, id, start_in):

        db = pscheduler.pg_connection(dsn)
        cursor = db.cursor()

        # Don't try to do anyting until the start time.
        sleep_time = pscheduler.timedelta_as_seconds(start_in)

        log.debug("%d: Sleeping %s until test start", id, sleep_time)
        time.sleep(sleep_time)

        cursor.execute("""
                       UPDATE run
                       SET state = run_state_running()
                       WHERE id = %s
                       """, [id])

        cursor.execute("""
                       SELECT
                           tool.name,
                           task.uuid,
                           task.id,
                           task.participant,
                           task.participants,
                           lower(run.times),
                           upper(run.times),
                           task.json #> '{test}',
                           run.uuid,
                           run.part_data_full
                       FROM
                           run
                           JOIN task ON task.id = run.task
                           JOIN tool ON tool.id = task.tool
                       WHERE run.id = %s
                       """, [id])

        # TODO: Should get exactly one row back.
        row = cursor.fetchone()

        tool, task_uuid, task_id, participant, participants, start, end, \
            test_spec, run_uuid, partdata = row

        #
        # Do the local tool run
        #

        if partdata is None:
            log.error("%s: Got NULL part_data_full", id)

        tool_input = {
            'schema': 1,
            'schedule': {
                'start': pscheduler.datetime_as_iso8601(start),
                'duration': pscheduler.timedelta_as_iso8601(end - start)
                },
            'test': test_spec,
            'participant': participant,
            'participant-data': partdata
            }

        tool_input = pscheduler.json_dump(tool_input, pretty=True)
        log.debug("%d: Testing with %s: %s", id, tool, tool_input)

        returncode, stdout, stderr = pscheduler.run_program(
            [ "pscheduler", "internal", "invoke", "tool", tool, "run" ],
            stdin = tool_input,
            # TODO: Make the overage on the timeout configurable, or
            # is a couple of seconds beyond what the tool said it
            # would take sufficient?
            timeout = pscheduler.timedelta_as_seconds(end - start) + 2
            )

        if len(stdout) == 0:
            stdout = None

        if len(stderr) == 0:
            stderr = None

        # TODO: Remove this.
        if returncode == 0:
            log.debug("%d: Test Succeeded: %s", id, stdout)
        else:
            log.debug("%d: Test failed %d: %s", id, returncode, stderr)


        # TODO: Put the task into the cleanup state and take the
        # automatic trigger out of the database.  Should go
        # direct to finished if not the lead participant.

        # TODO: Error check this.
        cursor.execute("""
                       UPDATE run
                       SET
                           status = %s,
                           result = %s,
                           errors = %s
                       WHERE id = %s
                       """,
                       [returncode,
                        stdout,
                        stderr,
                        id])


        # Note that the run happened.
        # TODO: Error check this.
        cursor.execute("SELECT task_register_run(%s)", [task_id])


        # The lead participant takes care of gathering and merging the finished results.

        if participant == 0:
           
            # Wait until the scheduled time has passed, which is the
            # only time we can be sure results might be available.

            time.sleep(pscheduler.time_until_seconds(end))

            # Fetch and combine the results.

            runs = [ pscheduler.api_url(host = host,
                                        path = '/tasks/%s/runs/%s'
                                        % (task_uuid, run_uuid) )
                     for host in participants ]


            full_result = []

            # Snooze a bit until the results are posted.
            # TODO: This is a race condition.  Need a true interlock.
            time.sleep(3)

            for run in runs:
                # TODO: This should try repeatedly
                r = requests.get(run)
                if r.status_code != 200:
                    raise Exception("Bad status code " + str(r.status_code)
                                    + ": " +  r.text)
                try:
                    full_result.append(pscheduler.json_load(str(r.text))['result'])
                except Exception as ex:
                    pscheduler.exception()
                    # TODO: This should produce a result indicating an error
                    full_result.append(None)

            log.debug("%d: Full result: %s",
                      id, pscheduler.json_dump(full_result, pretty=True))

            # Store the full result with each participant.

            full_params = {
                'run': pscheduler.json_dump({ 'result-full' : full_result })
                }

            for run in runs:
                log.debug("%d: Storing result in %s", id, run)
                r = requests.put(run, params=full_params)
                if r.status_code != 200:
                    raise Exception("Bad status code: " +  r.text)


        # TODO: Put the task into the finished state

        cursor.close()
        db.close()




#
# Main Program
#

# TODO: This should be encapsulated in something that catches
# exceptions and restarts (within reason).

pg = pscheduler.pg_connection(dsn)
cursor = pg.cursor()
cursor.execute("LISTEN " + options.channel)


while True:

    # Operate only on runs that are scheduled to start before the next
    # forced refresh.

    cursor.execute("""SELECT
                          run,
                          start_in
                      FROM
                          schedule_upcoming
                      WHERE
                          start_in < %s
                      ORDER BY start_in
                   """, [refresh]);

    if cursor.rowcount:
        # TODO: There must be a nicer way to take this array slice as args.
        rows = cursor.fetchall()
        log.debug(str([ "RUN " + str(row[0]) + " " + str(row[1]) for row in rows ]) )
        runs = [ Run(row[0], row[1]) for row in rows ]
        wait_time = rows[0][1]

        # Do this here to guarantee that we don't pick up rows for
        # runs we just started in the next iteration of the loop.

        cursor.execute( "UPDATE run SET state = run_state_on_deck() WHERE id in %s",
                    (tuple([row[0] for row in rows]),) )
        log.debug("Put %d runs on deck", len(runs))


    else:
        log.debug("Nothing to do.")
        runs = []
        wait_time = refresh


    if not pscheduler.timedelta_is_zero(wait_time):

        # Wait for a notification or the wait time to elapse.  Eat all
        # notifications as a group; we only care that we were notified.

        log.debug("Next run or check in %s", wait_time)

        # TODO: This try needs to be brought to the other programs.

        try:
            if select.select([pg],[],[],
                             pscheduler.timedelta_as_seconds(wait_time)) \
                             != ([],[],[]):
                # Notified
                pg.poll()
                del pg.notifies[:]
                log.debug("Schedule change.")

        except select.error as ex:

            err_no, message = ex
            if err_no != errno.EINTR:
                log.exception()
                raise ex


# Not that this will ever be reached...
pg.close()
